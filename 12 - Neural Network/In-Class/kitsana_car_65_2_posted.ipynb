{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":759},"executionInfo":{"elapsed":6208,"status":"ok","timestamp":1696391051760,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"FKh7u9X1nKmq","outputId":"64d4565b-f0d3-4a9a-b337-11cd7ea691cd"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Model</th>\n","      <th>Price</th>\n","      <th>Age_08_04</th>\n","      <th>Mfg_Month</th>\n","      <th>Mfg_Year</th>\n","      <th>KM</th>\n","      <th>Fuel_Type</th>\n","      <th>HP</th>\n","      <th>Automatic</th>\n","      <th>...</th>\n","      <th>Central_Lock</th>\n","      <th>Powered_Windows</th>\n","      <th>Power_Steering</th>\n","      <th>Radio</th>\n","      <th>Mistlamps</th>\n","      <th>Sport_Model</th>\n","      <th>Backseat_Divider</th>\n","      <th>Metallic_Rim</th>\n","      <th>Radio_cassette</th>\n","      <th>Tow_Bar</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1431</th>\n","      <td>1438</td>\n","      <td>TOYOTA Corolla 1.3 16V HATCHB G6 2/3-Doors</td>\n","      <td>7500</td>\n","      <td>69</td>\n","      <td>12</td>\n","      <td>1998</td>\n","      <td>20544</td>\n","      <td>Petrol</td>\n","      <td>86</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1432</th>\n","      <td>1439</td>\n","      <td>TOYOTA Corolla 1.3 16V HATCHB LINEA TERRA 2/3-...</td>\n","      <td>10845</td>\n","      <td>72</td>\n","      <td>9</td>\n","      <td>1998</td>\n","      <td>19000</td>\n","      <td>Petrol</td>\n","      <td>86</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1433</th>\n","      <td>1440</td>\n","      <td>TOYOTA Corolla 1.3 16V HATCHB LINEA TERRA 2/3-...</td>\n","      <td>8500</td>\n","      <td>71</td>\n","      <td>10</td>\n","      <td>1998</td>\n","      <td>17016</td>\n","      <td>Petrol</td>\n","      <td>86</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1434</th>\n","      <td>1441</td>\n","      <td>TOYOTA Corolla 1.3 16V HATCHB LINEA TERRA 2/3-...</td>\n","      <td>7250</td>\n","      <td>70</td>\n","      <td>11</td>\n","      <td>1998</td>\n","      <td>16916</td>\n","      <td>Petrol</td>\n","      <td>86</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1435</th>\n","      <td>1442</td>\n","      <td>TOYOTA Corolla 1.6 LB LINEA TERRA 4/5-Doors</td>\n","      <td>6950</td>\n","      <td>76</td>\n","      <td>5</td>\n","      <td>1998</td>\n","      <td>1</td>\n","      <td>Petrol</td>\n","      <td>110</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 34 columns</p>\n","</div>"],"text/plain":["        Id                                              Model  Price  \\\n","1431  1438         TOYOTA Corolla 1.3 16V HATCHB G6 2/3-Doors   7500   \n","1432  1439  TOYOTA Corolla 1.3 16V HATCHB LINEA TERRA 2/3-...  10845   \n","1433  1440  TOYOTA Corolla 1.3 16V HATCHB LINEA TERRA 2/3-...   8500   \n","1434  1441  TOYOTA Corolla 1.3 16V HATCHB LINEA TERRA 2/3-...   7250   \n","1435  1442        TOYOTA Corolla 1.6 LB LINEA TERRA 4/5-Doors   6950   \n","\n","      Age_08_04  Mfg_Month  Mfg_Year     KM Fuel_Type   HP  Automatic  ...  \\\n","1431         69         12      1998  20544    Petrol   86          0  ...   \n","1432         72          9      1998  19000    Petrol   86          0  ...   \n","1433         71         10      1998  17016    Petrol   86          0  ...   \n","1434         70         11      1998  16916    Petrol   86          0  ...   \n","1435         76          5      1998      1    Petrol  110          0  ...   \n","\n","      Central_Lock  Powered_Windows  Power_Steering  Radio  Mistlamps  \\\n","1431             1                1               1      0          1   \n","1432             0                0               1      0          0   \n","1433             0                0               1      0          0   \n","1434             0                0               0      0          0   \n","1435             0                0               1      0          0   \n","\n","      Sport_Model  Backseat_Divider  Metallic_Rim  Radio_cassette  Tow_Bar  \n","1431            1                 1             0               0        0  \n","1432            1                 1             0               0        0  \n","1433            0                 1             0               0        0  \n","1434            0                 1             0               0        0  \n","1435            0                 0             0               0        0  \n","\n","[5 rows x 34 columns]"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import pandas as pd\n","\n","import math\n","import matplotlib.pyplot as plt\n","from keras.layers import Dense\n","from keras.models import Sequential\n","from sklearn import preprocessing\n","\n","np.random.seed(1992)\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","\n","df = pd.read_excel(\"ToyotaCorolla.xls\", sheet_name=\"data\")\n","df.tail(5)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":395,"status":"ok","timestamp":1696292791981,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"WOi2OqJbcdeZ","outputId":"b4be428f-44b7-4f08-dea1-2b1d0b011ff4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Automatic_airco</th>\n","      <th>Boardcomputer</th>\n","      <th>KM</th>\n","      <th>Mfg_Year</th>\n","      <th>Price</th>\n","      <th>Weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>46986</td>\n","      <td>2002</td>\n","      <td>13500</td>\n","      <td>1165</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>72937</td>\n","      <td>2002</td>\n","      <td>13750</td>\n","      <td>1165</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>41711</td>\n","      <td>2002</td>\n","      <td>13950</td>\n","      <td>1165</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>48000</td>\n","      <td>2002</td>\n","      <td>14950</td>\n","      <td>1165</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>38500</td>\n","      <td>2002</td>\n","      <td>13750</td>\n","      <td>1170</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1431</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20544</td>\n","      <td>1998</td>\n","      <td>7500</td>\n","      <td>1025</td>\n","    </tr>\n","    <tr>\n","      <th>1432</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>19000</td>\n","      <td>1998</td>\n","      <td>10845</td>\n","      <td>1015</td>\n","    </tr>\n","    <tr>\n","      <th>1433</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>17016</td>\n","      <td>1998</td>\n","      <td>8500</td>\n","      <td>1015</td>\n","    </tr>\n","    <tr>\n","      <th>1434</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>16916</td>\n","      <td>1998</td>\n","      <td>7250</td>\n","      <td>1015</td>\n","    </tr>\n","    <tr>\n","      <th>1435</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1998</td>\n","      <td>6950</td>\n","      <td>1114</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1436 rows × 6 columns</p>\n","</div>"],"text/plain":["      Automatic_airco  Boardcomputer     KM  Mfg_Year  Price  Weight\n","0                   0              1  46986      2002  13500    1165\n","1                   0              1  72937      2002  13750    1165\n","2                   0              1  41711      2002  13950    1165\n","3                   0              1  48000      2002  14950    1165\n","4                   0              1  38500      2002  13750    1170\n","...               ...            ...    ...       ...    ...     ...\n","1431                0              0  20544      1998   7500    1025\n","1432                0              0  19000      1998  10845    1015\n","1433                0              0  17016      1998   8500    1015\n","1434                0              0  16916      1998   7250    1015\n","1435                0              0      1      1998   6950    1114\n","\n","[1436 rows x 6 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df = df[['Automatic_airco','Boardcomputer','KM', 'Mfg_Year', 'Price','Weight']]\n","df"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1696292798860,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"wDUMhWPaqU1y"},"outputs":[],"source":["X = df.drop(['Price'],axis=1).values\n","y = df.loc[:,'Price'].values"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":377,"status":"ok","timestamp":1696292846484,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"t74oHoYefl58","outputId":"b72a2fe6-3ff5-41e2-8756-935ca29208ff"},"outputs":[{"data":{"text/plain":["34"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# numrows = df.shape[0]\n","numcols = df.shape[1]\n","num_col = len(df.columns)\n","num_col"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":380,"status":"ok","timestamp":1696292868142,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"Qgofg9IWdSGy"},"outputs":[],"source":["xTrain , xTest , yTrain , yTest = train_test_split( X, y, train_size=0.7, random_state=1992 )"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":381,"status":"ok","timestamp":1696292872474,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"lfI2E9MRdhh6","outputId":"02aacdeb-9d49-437b-fa47-c3cf717a7cad"},"outputs":[{"data":{"text/plain":["(1005, 33)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["xTrain.shape"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":376,"status":"ok","timestamp":1696292893279,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"l9SH1kHDgn2q"},"outputs":[{"ename":"ValueError","evalue":"could not convert string to float: '\\xa0TOYOTA Corolla 1.6 VVTI Linea Terra liftback 4/5-Doors'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\WINDOWS I0\\Documents\\RapidMiner\\Local Repository\\01204465-DataMining\\12 - Neural Network\\In-Class\\kitsana_car_65_2_posted.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/WINDOWS%20I0/Documents/RapidMiner/Local%20Repository/01204465-DataMining/12%20-%20Neural%20Network/In-Class/kitsana_car_65_2_posted.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/WINDOWS%20I0/Documents/RapidMiner/Local%20Repository/01204465-DataMining/12%20-%20Neural%20Network/In-Class/kitsana_car_65_2_posted.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/WINDOWS%20I0/Documents/RapidMiner/Local%20Repository/01204465-DataMining/12%20-%20Neural%20Network/In-Class/kitsana_car_65_2_posted.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m xTrain \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mfit_transform( xTrain )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/WINDOWS%20I0/Documents/RapidMiner/Local%20Repository/01204465-DataMining/12%20-%20Neural%20Network/In-Class/kitsana_car_65_2_posted.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m xTest \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform( xTest )\n","File \u001b[1;32mc:\\Users\\WINDOWS I0\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n","File \u001b[1;32mc:\\Users\\WINDOWS I0\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n","File \u001b[1;32mc:\\Users\\WINDOWS I0\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:837\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    835\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 837\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n","File \u001b[1;32mc:\\Users\\WINDOWS I0\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\WINDOWS I0\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:873\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \n\u001b[0;32m    843\u001b[0m \u001b[39mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[39m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    872\u001b[0m first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 873\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    874\u001b[0m     X,\n\u001b[0;32m    875\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    876\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    877\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    878\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[0;32m    879\u001b[0m )\n\u001b[0;32m    880\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    882\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\WINDOWS I0\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n","File \u001b[1;32mc:\\Users\\WINDOWS I0\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    916\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    918\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    919\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    920\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    921\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\WINDOWS I0\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n","\u001b[1;31mValueError\u001b[0m: could not convert string to float: '\\xa0TOYOTA Corolla 1.6 VVTI Linea Terra liftback 4/5-Doors'"]}],"source":["# scaler\n","from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","xTrain = scaler.fit_transform( xTrain )\n","xTest = scaler.transform( xTest )"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":367,"status":"ok","timestamp":1696292897292,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"6xoR8pehgqMj","outputId":"405d311c-c5eb-4006-cea5-ed8c55eaff91"},"outputs":[{"data":{"text/plain":["(431, 33)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["xTest.shape"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":602,"status":"ok","timestamp":1696293162304,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"rcae9cS1nyk3","outputId":"67c023cc-749d-496f-c2ec-e0d95ec65030"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 10)                340       \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                110       \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 11        \n","                                                                 \n","=================================================================\n","Total params: 461 (1.80 KB)\n","Trainable params: 461 (1.80 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["from keras import optimizers\n","model = Sequential()\n","model.add(Dense(units=10,activation='relu', input_shape=(numcols-1,)))\n","model.add(Dense(units=10, activation='relu'))\n","model.add(Dense(1))\n","#model.compile(optimizer='adam',  loss='mean_squared_error')\n","#opt = optimizers.SGD(lr=0.01, momentum=0.0, decay=0.01)\n","opt = optimizers.Adam(learning_rate=0.01)\n","model.compile(optimizer=opt,  loss='mean_squared_error')\n","model.summary()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"executionInfo":{"elapsed":832,"status":"ok","timestamp":1696293405506,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"LyxqrZOcSkTz","outputId":"fe979992-b02b-4460-edab-a88d95acdd68"},"outputs":[{"name":"stdout","output_type":"stream","text":["You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"]}],"source":["#from keras.utils.vis_utils import plot_model\n","#plot_model(model,show_shapes=True, show_layer_names=True)\n","from tensorflow.keras.utils import plot_model\n","plot_model(model,show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":537,"status":"ok","timestamp":1696293180160,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"mlWx3SHre59N","outputId":"ddb0adc9-6ae6-4fb1-f7f5-4f12417f7781"},"outputs":[{"data":{"text/plain":["3"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["len(model.layers)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":592,"status":"ok","timestamp":1696293191731,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"rM_OWoX2raRw","outputId":"3d0a9dd5-8d4e-4edf-aff1-496a59e42d6e"},"outputs":[{"data":{"text/plain":["array([[-0.26079255, -0.65232807, -0.16224546,  0.23330784,  0.02501668],\n","       [-0.26079255,  1.53297097,  2.41006613,  0.87394823,  0.65899476],\n","       [ 3.83446541,  1.53297097, -1.8032625 ,  2.79586939,  1.02126794],\n","       ...,\n","       [-0.26079255, -0.65232807,  0.10797927, -1.04797293,  0.02501668],\n","       [ 3.83446541,  1.53297097, -1.67058543,  2.155229  ,  1.02126794],\n","       [-0.26079255,  1.53297097, -0.48620639,  0.87394823,  0.02501668]])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["xTrain"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":370,"status":"ok","timestamp":1696293194657,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"BzcCqVBmOr9O","outputId":"72c42817-0cf1-4725-eb20-17e23882a381"},"outputs":[{"data":{"text/plain":["(1005, 5)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["xTrain.shape"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42589,"status":"ok","timestamp":1696293248046,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"zS3BcnGLoW1s","outputId":"222e83f8-c99a-49e3-c27a-96507b786ab5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/300\n","11/11 [==============================] - 2s 25ms/step - loss: 130328752.0000 - val_loss: 129387840.0000\n","Epoch 2/300\n","11/11 [==============================] - 0s 5ms/step - loss: 130314272.0000 - val_loss: 129366968.0000\n","Epoch 3/300\n","11/11 [==============================] - 0s 5ms/step - loss: 130283648.0000 - val_loss: 129319384.0000\n","Epoch 4/300\n","11/11 [==============================] - 0s 5ms/step - loss: 130215240.0000 - val_loss: 129214528.0000\n","Epoch 5/300\n","11/11 [==============================] - 0s 5ms/step - loss: 130068512.0000 - val_loss: 129005152.0000\n","Epoch 6/300\n","11/11 [==============================] - 0s 6ms/step - loss: 129794904.0000 - val_loss: 128623024.0000\n","Epoch 7/300\n","11/11 [==============================] - 0s 6ms/step - loss: 129320264.0000 - val_loss: 127991832.0000\n","Epoch 8/300\n","11/11 [==============================] - 0s 6ms/step - loss: 128557072.0000 - val_loss: 127013096.0000\n","Epoch 9/300\n","11/11 [==============================] - 0s 6ms/step - loss: 127395376.0000 - val_loss: 125609208.0000\n","Epoch 10/300\n","11/11 [==============================] - 0s 18ms/step - loss: 125774688.0000 - val_loss: 123689280.0000\n","Epoch 11/300\n","11/11 [==============================] - 0s 8ms/step - loss: 123610440.0000 - val_loss: 121138816.0000\n","Epoch 12/300\n","11/11 [==============================] - 0s 5ms/step - loss: 120772040.0000 - val_loss: 117912688.0000\n","Epoch 13/300\n","11/11 [==============================] - 0s 6ms/step - loss: 117235176.0000 - val_loss: 113936480.0000\n","Epoch 14/300\n","11/11 [==============================] - 0s 6ms/step - loss: 112952888.0000 - val_loss: 109197376.0000\n","Epoch 15/300\n","11/11 [==============================] - 0s 6ms/step - loss: 107823248.0000 - val_loss: 103735680.0000\n","Epoch 16/300\n","11/11 [==============================] - 0s 6ms/step - loss: 102023576.0000 - val_loss: 97513456.0000\n","Epoch 17/300\n","11/11 [==============================] - 0s 14ms/step - loss: 95477848.0000 - val_loss: 90697312.0000\n","Epoch 18/300\n","11/11 [==============================] - 0s 10ms/step - loss: 88506040.0000 - val_loss: 83346624.0000\n","Epoch 19/300\n","11/11 [==============================] - 0s 8ms/step - loss: 80978112.0000 - val_loss: 75812256.0000\n","Epoch 20/300\n","11/11 [==============================] - 0s 18ms/step - loss: 73236888.0000 - val_loss: 68198640.0000\n","Epoch 21/300\n","11/11 [==============================] - 0s 8ms/step - loss: 65588908.0000 - val_loss: 60598520.0000\n","Epoch 22/300\n","11/11 [==============================] - 0s 7ms/step - loss: 57968004.0000 - val_loss: 53399576.0000\n","Epoch 23/300\n","11/11 [==============================] - 0s 6ms/step - loss: 50769572.0000 - val_loss: 46761936.0000\n","Epoch 24/300\n","11/11 [==============================] - 0s 5ms/step - loss: 44241704.0000 - val_loss: 40625760.0000\n","Epoch 25/300\n","11/11 [==============================] - 0s 6ms/step - loss: 38282876.0000 - val_loss: 35286396.0000\n","Epoch 26/300\n","11/11 [==============================] - 0s 7ms/step - loss: 33060700.0000 - val_loss: 30628920.0000\n","Epoch 27/300\n","11/11 [==============================] - 0s 5ms/step - loss: 28533618.0000 - val_loss: 26616502.0000\n","Epoch 28/300\n","11/11 [==============================] - 0s 5ms/step - loss: 24711654.0000 - val_loss: 23185890.0000\n","Epoch 29/300\n","11/11 [==============================] - 0s 5ms/step - loss: 21316590.0000 - val_loss: 20367466.0000\n","Epoch 30/300\n","11/11 [==============================] - 0s 6ms/step - loss: 18560388.0000 - val_loss: 17984124.0000\n","Epoch 31/300\n","11/11 [==============================] - 0s 5ms/step - loss: 16239406.0000 - val_loss: 15953527.0000\n","Epoch 32/300\n","11/11 [==============================] - 0s 16ms/step - loss: 14244744.0000 - val_loss: 14270792.0000\n","Epoch 33/300\n","11/11 [==============================] - 0s 9ms/step - loss: 12614532.0000 - val_loss: 12857731.0000\n","Epoch 34/300\n","11/11 [==============================] - 0s 10ms/step - loss: 11276410.0000 - val_loss: 11684576.0000\n","Epoch 35/300\n","11/11 [==============================] - 0s 41ms/step - loss: 10157665.0000 - val_loss: 10733759.0000\n","Epoch 36/300\n","11/11 [==============================] - 1s 52ms/step - loss: 9252312.0000 - val_loss: 9930104.0000\n","Epoch 37/300\n","11/11 [==============================] - 0s 22ms/step - loss: 8498506.0000 - val_loss: 9248178.0000\n","Epoch 38/300\n","11/11 [==============================] - 0s 19ms/step - loss: 7825312.0000 - val_loss: 8690459.0000\n","Epoch 39/300\n","11/11 [==============================] - 0s 7ms/step - loss: 7300993.5000 - val_loss: 8183424.0000\n","Epoch 40/300\n","11/11 [==============================] - 0s 7ms/step - loss: 6818910.5000 - val_loss: 7750181.0000\n","Epoch 41/300\n","11/11 [==============================] - 0s 7ms/step - loss: 6405269.0000 - val_loss: 7359107.0000\n","Epoch 42/300\n","11/11 [==============================] - 0s 6ms/step - loss: 6034046.5000 - val_loss: 7014357.0000\n","Epoch 43/300\n","11/11 [==============================] - 0s 6ms/step - loss: 5705522.5000 - val_loss: 6702785.5000\n","Epoch 44/300\n","11/11 [==============================] - 0s 5ms/step - loss: 5396828.5000 - val_loss: 6416720.0000\n","Epoch 45/300\n","11/11 [==============================] - 0s 4ms/step - loss: 5125511.5000 - val_loss: 6142320.0000\n","Epoch 46/300\n","11/11 [==============================] - 0s 5ms/step - loss: 4867076.5000 - val_loss: 5903065.0000\n","Epoch 47/300\n","11/11 [==============================] - 0s 5ms/step - loss: 4641530.5000 - val_loss: 5687489.0000\n","Epoch 48/300\n","11/11 [==============================] - 0s 5ms/step - loss: 4448108.0000 - val_loss: 5484887.0000\n","Epoch 49/300\n","11/11 [==============================] - 0s 5ms/step - loss: 4269943.5000 - val_loss: 5293406.5000\n","Epoch 50/300\n","11/11 [==============================] - 0s 5ms/step - loss: 4095559.2500 - val_loss: 5120897.0000\n","Epoch 51/300\n","11/11 [==============================] - 0s 5ms/step - loss: 3932201.7500 - val_loss: 4968150.5000\n","Epoch 52/300\n","11/11 [==============================] - 0s 5ms/step - loss: 3789014.5000 - val_loss: 4818819.5000\n","Epoch 53/300\n","11/11 [==============================] - 0s 5ms/step - loss: 3658840.2500 - val_loss: 4679665.5000\n","Epoch 54/300\n","11/11 [==============================] - 0s 5ms/step - loss: 3532659.0000 - val_loss: 4546880.0000\n","Epoch 55/300\n","11/11 [==============================] - 0s 5ms/step - loss: 3426503.2500 - val_loss: 4423192.5000\n","Epoch 56/300\n","11/11 [==============================] - 0s 5ms/step - loss: 3313952.7500 - val_loss: 4307563.5000\n","Epoch 57/300\n","11/11 [==============================] - 0s 5ms/step - loss: 3215425.5000 - val_loss: 4197483.0000\n","Epoch 58/300\n","11/11 [==============================] - 0s 5ms/step - loss: 3131012.7500 - val_loss: 4094505.2500\n","Epoch 59/300\n","11/11 [==============================] - 0s 5ms/step - loss: 3045700.7500 - val_loss: 3989538.2500\n","Epoch 60/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2967763.5000 - val_loss: 3900847.0000\n","Epoch 61/300\n","11/11 [==============================] - 0s 6ms/step - loss: 2888099.0000 - val_loss: 3810328.0000\n","Epoch 62/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2823790.2500 - val_loss: 3731134.0000\n","Epoch 63/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2762135.7500 - val_loss: 3657544.0000\n","Epoch 64/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2704103.0000 - val_loss: 3580240.2500\n","Epoch 65/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2650286.5000 - val_loss: 3518086.5000\n","Epoch 66/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2600599.5000 - val_loss: 3465041.2500\n","Epoch 67/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2558880.0000 - val_loss: 3415993.0000\n","Epoch 68/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2519345.0000 - val_loss: 3371496.0000\n","Epoch 69/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2485122.0000 - val_loss: 3333181.7500\n","Epoch 70/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2452896.2500 - val_loss: 3292006.2500\n","Epoch 71/300\n","11/11 [==============================] - 0s 8ms/step - loss: 2421669.0000 - val_loss: 3249657.7500\n","Epoch 72/300\n","11/11 [==============================] - 0s 7ms/step - loss: 2391228.7500 - val_loss: 3210945.5000\n","Epoch 73/300\n","11/11 [==============================] - 0s 6ms/step - loss: 2362961.5000 - val_loss: 3180963.5000\n","Epoch 74/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2336371.0000 - val_loss: 3139318.2500\n","Epoch 75/300\n","11/11 [==============================] - 0s 6ms/step - loss: 2315229.5000 - val_loss: 3103425.5000\n","Epoch 76/300\n","11/11 [==============================] - 0s 10ms/step - loss: 2285428.2500 - val_loss: 3076663.0000\n","Epoch 77/300\n","11/11 [==============================] - 0s 7ms/step - loss: 2263616.2500 - val_loss: 3052105.7500\n","Epoch 78/300\n","11/11 [==============================] - 0s 6ms/step - loss: 2242582.7500 - val_loss: 3029636.2500\n","Epoch 79/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2220212.7500 - val_loss: 3003717.2500\n","Epoch 80/300\n","11/11 [==============================] - 0s 9ms/step - loss: 2202653.7500 - val_loss: 2980194.0000\n","Epoch 81/300\n","11/11 [==============================] - 0s 7ms/step - loss: 2184562.0000 - val_loss: 2956424.0000\n","Epoch 82/300\n","11/11 [==============================] - 0s 8ms/step - loss: 2164343.7500 - val_loss: 2928660.7500\n","Epoch 83/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2147693.2500 - val_loss: 2906532.0000\n","Epoch 84/300\n","11/11 [==============================] - 0s 7ms/step - loss: 2133664.5000 - val_loss: 2877974.0000\n","Epoch 85/300\n","11/11 [==============================] - 0s 7ms/step - loss: 2117589.0000 - val_loss: 2851129.2500\n","Epoch 86/300\n","11/11 [==============================] - 0s 4ms/step - loss: 2104316.5000 - val_loss: 2824635.7500\n","Epoch 87/300\n","11/11 [==============================] - 0s 6ms/step - loss: 2091654.5000 - val_loss: 2802267.5000\n","Epoch 88/300\n","11/11 [==============================] - 0s 7ms/step - loss: 2079540.6250 - val_loss: 2781415.0000\n","Epoch 89/300\n","11/11 [==============================] - 0s 6ms/step - loss: 2068493.3750 - val_loss: 2756060.2500\n","Epoch 90/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2053836.2500 - val_loss: 2742491.0000\n","Epoch 91/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2040525.6250 - val_loss: 2710267.2500\n","Epoch 92/300\n","11/11 [==============================] - 0s 6ms/step - loss: 2032603.2500 - val_loss: 2688446.7500\n","Epoch 93/300\n","11/11 [==============================] - 0s 6ms/step - loss: 2019474.6250 - val_loss: 2672285.0000\n","Epoch 94/300\n","11/11 [==============================] - 0s 5ms/step - loss: 2010159.1250 - val_loss: 2653426.0000\n","Epoch 95/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1999360.3750 - val_loss: 2637175.5000\n","Epoch 96/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1988680.8750 - val_loss: 2615976.7500\n","Epoch 97/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1978696.8750 - val_loss: 2601700.7500\n","Epoch 98/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1972533.8750 - val_loss: 2591421.2500\n","Epoch 99/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1972167.5000 - val_loss: 2556885.5000\n","Epoch 100/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1952527.2500 - val_loss: 2538600.5000\n","Epoch 101/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1942069.2500 - val_loss: 2526068.0000\n","Epoch 102/300\n","11/11 [==============================] - 0s 8ms/step - loss: 1934892.5000 - val_loss: 2513688.0000\n","Epoch 103/300\n","11/11 [==============================] - 0s 10ms/step - loss: 1924325.7500 - val_loss: 2495487.7500\n","Epoch 104/300\n","11/11 [==============================] - 0s 14ms/step - loss: 1915426.2500 - val_loss: 2484268.2500\n","Epoch 105/300\n","11/11 [==============================] - 0s 21ms/step - loss: 1907534.1250 - val_loss: 2470482.0000\n","Epoch 106/300\n","11/11 [==============================] - 0s 8ms/step - loss: 1899920.3750 - val_loss: 2453187.0000\n","Epoch 107/300\n","11/11 [==============================] - 0s 11ms/step - loss: 1892004.0000 - val_loss: 2442001.2500\n","Epoch 108/300\n","11/11 [==============================] - 0s 12ms/step - loss: 1884062.2500 - val_loss: 2430698.0000\n","Epoch 109/300\n","11/11 [==============================] - 0s 9ms/step - loss: 1875757.6250 - val_loss: 2416391.7500\n","Epoch 110/300\n","11/11 [==============================] - 0s 8ms/step - loss: 1870712.3750 - val_loss: 2400339.7500\n","Epoch 111/300\n","11/11 [==============================] - 0s 13ms/step - loss: 1867319.8750 - val_loss: 2394926.5000\n","Epoch 112/300\n","11/11 [==============================] - 0s 20ms/step - loss: 1855634.6250 - val_loss: 2368610.0000\n","Epoch 113/300\n","11/11 [==============================] - 0s 35ms/step - loss: 1851810.7500 - val_loss: 2352683.2500\n","Epoch 114/300\n","11/11 [==============================] - 0s 9ms/step - loss: 1842959.3750 - val_loss: 2342174.2500\n","Epoch 115/300\n","11/11 [==============================] - 0s 16ms/step - loss: 1837456.1250 - val_loss: 2328811.2500\n","Epoch 116/300\n","11/11 [==============================] - 0s 9ms/step - loss: 1830888.3750 - val_loss: 2321248.0000\n","Epoch 117/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1826828.1250 - val_loss: 2313601.7500\n","Epoch 118/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1822296.0000 - val_loss: 2308560.2500\n","Epoch 119/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1810811.2500 - val_loss: 2286978.7500\n","Epoch 120/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1805510.0000 - val_loss: 2275827.7500\n","Epoch 121/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1801957.7500 - val_loss: 2263178.2500\n","Epoch 122/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1796276.6250 - val_loss: 2253399.0000\n","Epoch 123/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1789766.3750 - val_loss: 2246305.2500\n","Epoch 124/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1788971.0000 - val_loss: 2242959.2500\n","Epoch 125/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1779163.2500 - val_loss: 2228597.5000\n","Epoch 126/300\n","11/11 [==============================] - 0s 9ms/step - loss: 1772412.7500 - val_loss: 2209273.7500\n","Epoch 127/300\n","11/11 [==============================] - 0s 11ms/step - loss: 1775952.8750 - val_loss: 2199069.0000\n","Epoch 128/300\n","11/11 [==============================] - 0s 8ms/step - loss: 1766951.0000 - val_loss: 2191438.0000\n","Epoch 129/300\n","11/11 [==============================] - 0s 14ms/step - loss: 1762091.5000 - val_loss: 2186093.7500\n","Epoch 130/300\n","11/11 [==============================] - 0s 13ms/step - loss: 1758116.1250 - val_loss: 2180172.0000\n","Epoch 131/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1748915.7500 - val_loss: 2163371.5000\n","Epoch 132/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1746327.2500 - val_loss: 2149443.7500\n","Epoch 133/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1742662.1250 - val_loss: 2146446.7500\n","Epoch 134/300\n","11/11 [==============================] - 0s 9ms/step - loss: 1735312.1250 - val_loss: 2139346.0000\n","Epoch 135/300\n","11/11 [==============================] - 0s 8ms/step - loss: 1733291.7500 - val_loss: 2129498.5000\n","Epoch 136/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1726491.0000 - val_loss: 2122228.0000\n","Epoch 137/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1725001.2500 - val_loss: 2113931.5000\n","Epoch 138/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1719152.2500 - val_loss: 2107561.0000\n","Epoch 139/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1715376.2500 - val_loss: 2101859.7500\n","Epoch 140/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1711857.5000 - val_loss: 2097387.2500\n","Epoch 141/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1710061.5000 - val_loss: 2093532.8750\n","Epoch 142/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1704829.7500 - val_loss: 2085596.0000\n","Epoch 143/300\n","11/11 [==============================] - 0s 10ms/step - loss: 1702100.8750 - val_loss: 2081236.6250\n","Epoch 144/300\n","11/11 [==============================] - 0s 12ms/step - loss: 1698979.7500 - val_loss: 2070116.2500\n","Epoch 145/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1694990.8750 - val_loss: 2061581.5000\n","Epoch 146/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1691774.2500 - val_loss: 2054798.1250\n","Epoch 147/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1691113.3750 - val_loss: 2055656.8750\n","Epoch 148/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1685622.1250 - val_loss: 2046755.1250\n","Epoch 149/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1681191.1250 - val_loss: 2039765.3750\n","Epoch 150/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1678164.6250 - val_loss: 2031554.1250\n","Epoch 151/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1676909.7500 - val_loss: 2031653.7500\n","Epoch 152/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1670994.3750 - val_loss: 2016629.3750\n","Epoch 153/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1668372.8750 - val_loss: 2009663.3750\n","Epoch 154/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1667737.8750 - val_loss: 2002536.1250\n","Epoch 155/300\n","11/11 [==============================] - 0s 14ms/step - loss: 1662992.8750 - val_loss: 1996768.7500\n","Epoch 156/300\n","11/11 [==============================] - 0s 21ms/step - loss: 1660642.7500 - val_loss: 1992557.6250\n","Epoch 157/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1657704.2500 - val_loss: 1986193.0000\n","Epoch 158/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1654637.0000 - val_loss: 1983293.6250\n","Epoch 159/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1651733.5000 - val_loss: 1982188.0000\n","Epoch 160/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1649362.0000 - val_loss: 1977078.5000\n","Epoch 161/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1648301.6250 - val_loss: 1968323.1250\n","Epoch 162/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1643281.1250 - val_loss: 1965193.6250\n","Epoch 163/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1640363.0000 - val_loss: 1958984.6250\n","Epoch 164/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1639315.7500 - val_loss: 1959966.6250\n","Epoch 165/300\n","11/11 [==============================] - 0s 19ms/step - loss: 1638916.6250 - val_loss: 1944606.2500\n","Epoch 166/300\n","11/11 [==============================] - 0s 26ms/step - loss: 1637229.1250 - val_loss: 1936736.2500\n","Epoch 167/300\n","11/11 [==============================] - 0s 10ms/step - loss: 1630833.8750 - val_loss: 1935062.7500\n","Epoch 168/300\n","11/11 [==============================] - 0s 32ms/step - loss: 1629653.3750 - val_loss: 1934766.2500\n","Epoch 169/300\n","11/11 [==============================] - 0s 19ms/step - loss: 1628155.3750 - val_loss: 1931711.7500\n","Epoch 170/300\n","11/11 [==============================] - 0s 11ms/step - loss: 1628609.3750 - val_loss: 1932841.8750\n","Epoch 171/300\n","11/11 [==============================] - 0s 12ms/step - loss: 1627392.0000 - val_loss: 1922472.1250\n","Epoch 172/300\n","11/11 [==============================] - 0s 9ms/step - loss: 1621188.5000 - val_loss: 1917427.2500\n","Epoch 173/300\n","11/11 [==============================] - 0s 11ms/step - loss: 1619001.2500 - val_loss: 1916360.8750\n","Epoch 174/300\n","11/11 [==============================] - 0s 23ms/step - loss: 1617419.6250 - val_loss: 1912986.6250\n","Epoch 175/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1617552.7500 - val_loss: 1905545.6250\n","Epoch 176/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1617042.6250 - val_loss: 1906685.6250\n","Epoch 177/300\n","11/11 [==============================] - 0s 11ms/step - loss: 1613264.2500 - val_loss: 1901617.1250\n","Epoch 178/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1612027.0000 - val_loss: 1896396.3750\n","Epoch 179/300\n","11/11 [==============================] - 0s 11ms/step - loss: 1610886.8750 - val_loss: 1889576.6250\n","Epoch 180/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1607902.1250 - val_loss: 1890403.5000\n","Epoch 181/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1606435.0000 - val_loss: 1888627.8750\n","Epoch 182/300\n","11/11 [==============================] - 0s 31ms/step - loss: 1607310.1250 - val_loss: 1892277.2500\n","Epoch 183/300\n","11/11 [==============================] - 0s 9ms/step - loss: 1602976.1250 - val_loss: 1884996.2500\n","Epoch 184/300\n","11/11 [==============================] - 0s 9ms/step - loss: 1602103.5000 - val_loss: 1881506.1250\n","Epoch 185/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1601467.3750 - val_loss: 1875641.0000\n","Epoch 186/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1600044.7500 - val_loss: 1878824.6250\n","Epoch 187/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1596343.3750 - val_loss: 1871574.5000\n","Epoch 188/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1599483.3750 - val_loss: 1870299.6250\n","Epoch 189/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1593298.2500 - val_loss: 1866742.1250\n","Epoch 190/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1593802.8750 - val_loss: 1869778.7500\n","Epoch 191/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1593199.1250 - val_loss: 1859269.2500\n","Epoch 192/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1591381.3750 - val_loss: 1855824.7500\n","Epoch 193/300\n","11/11 [==============================] - 0s 9ms/step - loss: 1587598.6250 - val_loss: 1859398.5000\n","Epoch 194/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1588085.5000 - val_loss: 1865916.1250\n","Epoch 195/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1585987.7500 - val_loss: 1858129.5000\n","Epoch 196/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1582939.6250 - val_loss: 1851271.0000\n","Epoch 197/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1581358.6250 - val_loss: 1848265.2500\n","Epoch 198/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1581416.6250 - val_loss: 1847410.7500\n","Epoch 199/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1585035.2500 - val_loss: 1850505.8750\n","Epoch 200/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1578920.0000 - val_loss: 1849481.0000\n","Epoch 201/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1577534.7500 - val_loss: 1835545.2500\n","Epoch 202/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1577480.0000 - val_loss: 1829918.2500\n","Epoch 203/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1574415.2500 - val_loss: 1829826.1250\n","Epoch 204/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1574548.1250 - val_loss: 1833242.6250\n","Epoch 205/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1572646.0000 - val_loss: 1825525.0000\n","Epoch 206/300\n","11/11 [==============================] - 0s 4ms/step - loss: 1569907.1250 - val_loss: 1823050.6250\n","Epoch 207/300\n","11/11 [==============================] - 0s 4ms/step - loss: 1570789.0000 - val_loss: 1821809.3750\n","Epoch 208/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1570817.2500 - val_loss: 1824316.7500\n","Epoch 209/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1568725.5000 - val_loss: 1820068.0000\n","Epoch 210/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1566924.8750 - val_loss: 1822953.2500\n","Epoch 211/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1565624.2500 - val_loss: 1817313.3750\n","Epoch 212/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1564377.8750 - val_loss: 1814979.1250\n","Epoch 213/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1564783.2500 - val_loss: 1813303.3750\n","Epoch 214/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1563394.1250 - val_loss: 1814279.8750\n","Epoch 215/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1563047.1250 - val_loss: 1811672.6250\n","Epoch 216/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1560437.5000 - val_loss: 1811469.2500\n","Epoch 217/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1563272.5000 - val_loss: 1807635.2500\n","Epoch 218/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1560974.7500 - val_loss: 1808566.0000\n","Epoch 219/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1556748.5000 - val_loss: 1805239.0000\n","Epoch 220/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1556772.1250 - val_loss: 1806044.5000\n","Epoch 221/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1556872.5000 - val_loss: 1806026.0000\n","Epoch 222/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1553852.1250 - val_loss: 1805779.8750\n","Epoch 223/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1555064.1250 - val_loss: 1806485.7500\n","Epoch 224/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1561191.0000 - val_loss: 1800828.7500\n","Epoch 225/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1554584.5000 - val_loss: 1807053.8750\n","Epoch 226/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1553961.6250 - val_loss: 1805372.8750\n","Epoch 227/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1551261.5000 - val_loss: 1803829.3750\n","Epoch 228/300\n","11/11 [==============================] - 0s 12ms/step - loss: 1555912.8750 - val_loss: 1793628.0000\n","Epoch 229/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1549153.6250 - val_loss: 1791627.0000\n","Epoch 230/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1555550.3750 - val_loss: 1794148.6250\n","Epoch 231/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1547199.0000 - val_loss: 1790342.5000\n","Epoch 232/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1547902.1250 - val_loss: 1790351.6250\n","Epoch 233/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1547916.6250 - val_loss: 1790208.7500\n","Epoch 234/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1547179.3750 - val_loss: 1784278.3750\n","Epoch 235/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1545584.7500 - val_loss: 1785178.3750\n","Epoch 236/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1546762.7500 - val_loss: 1788940.7500\n","Epoch 237/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1544300.8750 - val_loss: 1789172.8750\n","Epoch 238/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1546287.3750 - val_loss: 1787552.7500\n","Epoch 239/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1542637.7500 - val_loss: 1786246.3750\n","Epoch 240/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1542105.2500 - val_loss: 1784320.2500\n","Epoch 241/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1542510.7500 - val_loss: 1785782.7500\n","Epoch 242/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1542131.3750 - val_loss: 1781690.2500\n","Epoch 243/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1540837.0000 - val_loss: 1784363.0000\n","Epoch 244/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1538008.8750 - val_loss: 1775670.7500\n","Epoch 245/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1539169.0000 - val_loss: 1768356.0000\n","Epoch 246/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1539522.7500 - val_loss: 1766373.3750\n","Epoch 247/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1538943.1250 - val_loss: 1764386.3750\n","Epoch 248/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1535998.2500 - val_loss: 1766842.2500\n","Epoch 249/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1537789.1250 - val_loss: 1769183.0000\n","Epoch 250/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1537488.1250 - val_loss: 1767865.6250\n","Epoch 251/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1537711.3750 - val_loss: 1766752.2500\n","Epoch 252/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1535802.1250 - val_loss: 1757996.1250\n","Epoch 253/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1537408.8750 - val_loss: 1760984.2500\n","Epoch 254/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1533011.1250 - val_loss: 1759784.5000\n","Epoch 255/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1534246.8750 - val_loss: 1758341.0000\n","Epoch 256/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1532017.8750 - val_loss: 1757098.6250\n","Epoch 257/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1533005.7500 - val_loss: 1759739.3750\n","Epoch 258/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1529934.8750 - val_loss: 1756157.8750\n","Epoch 259/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1530275.7500 - val_loss: 1751596.7500\n","Epoch 260/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1529502.7500 - val_loss: 1752515.2500\n","Epoch 261/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1533428.1250 - val_loss: 1762929.3750\n","Epoch 262/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1527419.6250 - val_loss: 1757712.0000\n","Epoch 263/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1528112.8750 - val_loss: 1751247.2500\n","Epoch 264/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1528804.2500 - val_loss: 1752065.0000\n","Epoch 265/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1528996.7500 - val_loss: 1761434.6250\n","Epoch 266/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1527335.5000 - val_loss: 1753098.0000\n","Epoch 267/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1525494.5000 - val_loss: 1752415.6250\n","Epoch 268/300\n","11/11 [==============================] - 0s 7ms/step - loss: 1523291.7500 - val_loss: 1753369.0000\n","Epoch 269/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1527179.5000 - val_loss: 1760462.1250\n","Epoch 270/300\n","11/11 [==============================] - 0s 8ms/step - loss: 1523693.5000 - val_loss: 1753634.8750\n","Epoch 271/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1525720.0000 - val_loss: 1746756.3750\n","Epoch 272/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1525102.0000 - val_loss: 1752921.2500\n","Epoch 273/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1519948.8750 - val_loss: 1746652.3750\n","Epoch 274/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1519870.6250 - val_loss: 1745340.7500\n","Epoch 275/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1520350.0000 - val_loss: 1747118.2500\n","Epoch 276/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1518338.7500 - val_loss: 1747325.1250\n","Epoch 277/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1519100.3750 - val_loss: 1742427.6250\n","Epoch 278/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1519916.6250 - val_loss: 1741858.5000\n","Epoch 279/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1519978.1250 - val_loss: 1746418.5000\n","Epoch 280/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1521492.2500 - val_loss: 1747319.0000\n","Epoch 281/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1518078.6250 - val_loss: 1742596.2500\n","Epoch 282/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1518000.8750 - val_loss: 1749689.2500\n","Epoch 283/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1519523.0000 - val_loss: 1745249.3750\n","Epoch 284/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1515623.1250 - val_loss: 1743273.5000\n","Epoch 285/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1517590.8750 - val_loss: 1746348.0000\n","Epoch 286/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1519478.1250 - val_loss: 1739482.7500\n","Epoch 287/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1519032.3750 - val_loss: 1737695.7500\n","Epoch 288/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1514275.2500 - val_loss: 1740867.5000\n","Epoch 289/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1513439.2500 - val_loss: 1739329.3750\n","Epoch 290/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1517954.2500 - val_loss: 1736402.8750\n","Epoch 291/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1517829.1250 - val_loss: 1741843.2500\n","Epoch 292/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1516663.5000 - val_loss: 1741740.8750\n","Epoch 293/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1518687.3750 - val_loss: 1734999.0000\n","Epoch 294/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1511320.0000 - val_loss: 1736412.8750\n","Epoch 295/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1512064.0000 - val_loss: 1733222.7500\n","Epoch 296/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1511907.6250 - val_loss: 1734993.8750\n","Epoch 297/300\n","11/11 [==============================] - 0s 6ms/step - loss: 1511408.7500 - val_loss: 1738531.8750\n","Epoch 298/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1510876.6250 - val_loss: 1739154.3750\n","Epoch 299/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1514379.1250 - val_loss: 1734286.2500\n","Epoch 300/300\n","11/11 [==============================] - 0s 5ms/step - loss: 1510073.8750 - val_loss: 1733921.5000\n"]}],"source":["#model.fit(xTrain, yTrain, batch_size=64, epochs=300)\n","#history = model.fit(xTrain, yTrain, batch_size=64, epochs=300)\n","history = model.fit(xTrain, yTrain, validation_split=0.33, batch_size=64, epochs=300)\n","#history = model.fit(xTrain, yTrain, validation_split=0.33, batch_size=64, epochs=1500)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":456,"status":"ok","timestamp":1696293421672,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"ZzzoByXBosEr","outputId":"9a3252f9-1ead-4e4f-8393-f1d36d8b78c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["14/14 [==============================] - 0s 2ms/step\n"]}],"source":["#make prediction\n","y_pred = model.predict(xTest)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":371,"status":"ok","timestamp":1696293432302,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"GPEm1KcEsQLM","outputId":"998f3a18-385a-4f81-9594-828c885f59cf"},"outputs":[{"data":{"text/plain":["array([[ 9191.34  ],\n","       [ 6939.226 ],\n","       [18003.447 ],\n","       [ 9046.256 ],\n","       [ 8211.47  ],\n","       [13260.017 ],\n","       [ 7660.2056],\n","       [11146.804 ],\n","       [ 7927.02  ],\n","       [ 9524.791 ],\n","       [ 9038.323 ],\n","       [ 9958.032 ],\n","       [12384.044 ],\n","       [ 8286.849 ],\n","       [ 8437.553 ],\n","       [ 9583.012 ],\n","       [ 9009.53  ],\n","       [ 8406.474 ],\n","       [14262.699 ],\n","       [12991.685 ],\n","       [ 7210.07  ],\n","       [10114.501 ],\n","       [11647.211 ],\n","       [ 9492.976 ],\n","       [12729.198 ],\n","       [ 7819.3735],\n","       [10811.487 ],\n","       [11334.548 ],\n","       [ 8285.495 ],\n","       [ 8796.604 ],\n","       [ 7983.4126],\n","       [ 9024.8   ],\n","       [ 7338.8247],\n","       [ 8488.924 ],\n","       [ 8621.958 ],\n","       [13252.724 ],\n","       [ 9212.766 ],\n","       [13174.744 ],\n","       [12835.677 ],\n","       [10937.157 ],\n","       [ 9261.929 ],\n","       [ 8376.866 ],\n","       [ 9726.808 ],\n","       [10400.813 ],\n","       [ 9195.471 ],\n","       [13165.194 ],\n","       [ 8295.833 ],\n","       [ 8638.494 ],\n","       [ 8243.692 ],\n","       [15561.21  ],\n","       [ 8872.626 ],\n","       [ 8357.363 ],\n","       [13044.128 ],\n","       [ 9801.929 ],\n","       [11065.294 ],\n","       [11092.162 ],\n","       [12000.847 ],\n","       [12068.202 ],\n","       [20194.926 ],\n","       [ 9314.945 ],\n","       [ 8309.613 ],\n","       [10098.493 ],\n","       [ 8915.308 ],\n","       [10353.124 ],\n","       [14677.944 ],\n","       [ 9425.554 ],\n","       [10008.65  ],\n","       [ 7813.7026],\n","       [ 8270.833 ],\n","       [16548.652 ],\n","       [ 7956.2246],\n","       [ 9542.43  ],\n","       [10362.339 ],\n","       [ 8767.055 ],\n","       [ 6684.488 ],\n","       [ 8681.933 ],\n","       [ 7854.1465],\n","       [ 7958.5366],\n","       [12522.505 ],\n","       [25386.795 ],\n","       [ 9058.653 ],\n","       [10905.785 ],\n","       [ 8977.295 ],\n","       [ 7780.155 ],\n","       [21646.877 ],\n","       [ 8992.196 ],\n","       [10695.348 ],\n","       [ 6680.3784],\n","       [20229.74  ],\n","       [11084.857 ],\n","       [ 7133.681 ],\n","       [10789.909 ],\n","       [ 9101.988 ],\n","       [11069.37  ],\n","       [ 7842.9946],\n","       [ 8677.632 ],\n","       [13188.425 ],\n","       [ 9027.522 ],\n","       [ 8601.965 ],\n","       [ 8125.373 ],\n","       [10013.517 ],\n","       [12119.933 ],\n","       [ 8715.599 ],\n","       [ 9864.912 ],\n","       [ 8848.867 ],\n","       [ 8090.424 ],\n","       [10468.192 ],\n","       [ 8582.257 ],\n","       [ 9129.588 ],\n","       [18979.98  ],\n","       [18009.41  ],\n","       [10545.796 ],\n","       [12896.298 ],\n","       [ 8728.338 ],\n","       [ 7948.3906],\n","       [ 9422.837 ],\n","       [ 7886.39  ],\n","       [13456.34  ],\n","       [13322.151 ],\n","       [ 8484.044 ],\n","       [ 8022.571 ],\n","       [10632.166 ],\n","       [ 9379.2   ],\n","       [ 8808.144 ],\n","       [ 8447.66  ],\n","       [ 9200.011 ],\n","       [14952.934 ],\n","       [ 9587.335 ],\n","       [ 9696.586 ],\n","       [ 8913.081 ],\n","       [12435.358 ],\n","       [ 8874.545 ],\n","       [ 8860.481 ],\n","       [ 8576.069 ],\n","       [11911.075 ],\n","       [ 7674.4033],\n","       [ 8680.345 ],\n","       [16093.671 ],\n","       [12988.362 ],\n","       [ 9585.728 ],\n","       [ 9061.649 ],\n","       [24988.621 ],\n","       [16122.633 ],\n","       [ 7519.1646],\n","       [11195.782 ],\n","       [10691.298 ],\n","       [10629.913 ],\n","       [ 8509.288 ],\n","       [12327.194 ],\n","       [ 8512.769 ],\n","       [ 7156.7046],\n","       [ 8968.989 ],\n","       [ 7664.651 ],\n","       [ 9256.572 ],\n","       [11799.546 ],\n","       [ 7782.261 ],\n","       [10215.404 ],\n","       [ 9354.535 ],\n","       [10690.505 ],\n","       [10617.915 ],\n","       [ 8763.249 ],\n","       [12091.659 ],\n","       [ 7917.384 ],\n","       [ 7742.1836],\n","       [12684.874 ],\n","       [ 7704.897 ],\n","       [ 7995.369 ],\n","       [ 8184.9233],\n","       [ 9296.3125],\n","       [10396.753 ],\n","       [ 9914.702 ],\n","       [ 9851.791 ],\n","       [ 9372.467 ],\n","       [ 7521.013 ],\n","       [ 8852.078 ],\n","       [ 8510.534 ],\n","       [ 8716.181 ],\n","       [ 8996.614 ],\n","       [17083.797 ],\n","       [17123.688 ],\n","       [ 8775.638 ],\n","       [ 8189.595 ],\n","       [10443.064 ],\n","       [ 8344.794 ],\n","       [ 8956.302 ],\n","       [ 8081.638 ],\n","       [ 9182.329 ],\n","       [ 7507.201 ],\n","       [ 9039.688 ],\n","       [16606.059 ],\n","       [ 8205.423 ],\n","       [ 8288.09  ],\n","       [12037.437 ],\n","       [ 9306.518 ],\n","       [ 8750.8   ],\n","       [ 9203.833 ],\n","       [ 9307.566 ],\n","       [ 7422.293 ],\n","       [16825.453 ],\n","       [13001.722 ],\n","       [ 8340.706 ],\n","       [ 8716.181 ],\n","       [16816.887 ],\n","       [ 8539.1875],\n","       [ 8081.018 ],\n","       [10751.507 ],\n","       [15702.277 ],\n","       [ 8692.936 ],\n","       [ 9444.964 ],\n","       [ 9365.299 ],\n","       [12877.232 ],\n","       [ 8327.684 ],\n","       [ 8798.799 ],\n","       [13136.288 ],\n","       [ 8486.587 ],\n","       [16275.868 ],\n","       [ 8306.4795],\n","       [ 8183.7593],\n","       [ 8816.538 ],\n","       [22794.791 ],\n","       [ 9301.169 ],\n","       [ 8430.921 ],\n","       [ 8316.95  ],\n","       [ 8068.1104],\n","       [12752.52  ],\n","       [ 8921.193 ],\n","       [ 7865.5547],\n","       [ 8730.804 ],\n","       [ 7811.0054],\n","       [12947.338 ],\n","       [11308.722 ],\n","       [ 7361.161 ],\n","       [18058.754 ],\n","       [10897.246 ],\n","       [ 8177.612 ],\n","       [ 9425.554 ],\n","       [ 8266.38  ],\n","       [ 8183.279 ],\n","       [ 9886.987 ],\n","       [16123.747 ],\n","       [ 8602.667 ],\n","       [ 8530.916 ],\n","       [16730.318 ],\n","       [ 8741.507 ],\n","       [10577.08  ],\n","       [11144.97  ],\n","       [ 7590.2075],\n","       [ 8792.038 ],\n","       [ 9757.0625],\n","       [ 9632.108 ],\n","       [11120.565 ],\n","       [12737.567 ],\n","       [ 8309.995 ],\n","       [ 8340.882 ],\n","       [10311.067 ],\n","       [ 8385.133 ],\n","       [11216.119 ],\n","       [15736.3545],\n","       [10167.2   ],\n","       [ 7962.9717],\n","       [11007.423 ],\n","       [ 7881.9727],\n","       [17215.58  ],\n","       [ 7697.9316],\n","       [10738.2295],\n","       [ 8575.132 ],\n","       [14760.911 ],\n","       [ 7723.0796],\n","       [11618.468 ],\n","       [10129.468 ],\n","       [13451.266 ],\n","       [12171.146 ],\n","       [ 7995.8916],\n","       [ 9621.055 ],\n","       [11479.777 ],\n","       [ 8249.039 ],\n","       [10863.416 ],\n","       [ 8555.951 ],\n","       [ 8703.95  ],\n","       [ 8659.845 ],\n","       [ 9032.321 ],\n","       [10836.747 ],\n","       [ 9811.67  ],\n","       [ 9097.78  ],\n","       [12541.175 ],\n","       [ 8013.3555],\n","       [ 9010.177 ],\n","       [10842.523 ],\n","       [12443.481 ],\n","       [ 8123.2056],\n","       [ 7562.6074],\n","       [ 8010.1235],\n","       [ 7311.678 ],\n","       [12603.169 ],\n","       [11990.735 ],\n","       [ 8433.04  ],\n","       [11764.861 ],\n","       [ 9569.671 ],\n","       [12646.56  ],\n","       [13643.514 ],\n","       [ 8526.54  ],\n","       [10003.232 ],\n","       [ 9087.764 ],\n","       [12128.98  ],\n","       [ 9478.161 ],\n","       [16339.911 ],\n","       [ 8117.0845],\n","       [12540.024 ],\n","       [10227.86  ],\n","       [ 8787.388 ],\n","       [11351.609 ],\n","       [10929.4795],\n","       [10050.577 ],\n","       [10267.527 ],\n","       [ 9156.549 ],\n","       [ 8314.435 ],\n","       [14554.989 ],\n","       [ 9089.386 ],\n","       [ 7814.98  ],\n","       [ 8415.862 ],\n","       [12442.291 ],\n","       [13388.417 ],\n","       [10659.098 ],\n","       [ 8077.815 ],\n","       [10245.277 ],\n","       [ 8109.734 ],\n","       [ 9978.584 ],\n","       [ 8655.221 ],\n","       [11067.171 ],\n","       [18443.125 ],\n","       [15320.309 ],\n","       [ 7965.482 ],\n","       [ 7867.3584],\n","       [ 8784.653 ],\n","       [ 9039.817 ],\n","       [ 9798.96  ],\n","       [ 7771.38  ],\n","       [ 8444.022 ],\n","       [ 9640.001 ],\n","       [ 9358.001 ],\n","       [ 9677.252 ],\n","       [20517.828 ],\n","       [12031.059 ],\n","       [ 9449.669 ],\n","       [19140.973 ],\n","       [ 8339.07  ],\n","       [ 9405.6045],\n","       [ 7692.8896],\n","       [10447.263 ],\n","       [ 7835.6904],\n","       [19644.506 ],\n","       [ 8261.436 ],\n","       [ 8428.37  ],\n","       [ 8040.0273],\n","       [ 8456.987 ],\n","       [ 9862.931 ],\n","       [ 9731.29  ],\n","       [ 9063.482 ],\n","       [ 7835.4663],\n","       [11259.392 ],\n","       [ 9451.636 ],\n","       [22247.686 ],\n","       [11919.4   ],\n","       [ 8105.696 ],\n","       [16117.794 ],\n","       [ 9450.071 ],\n","       [ 7709.1353],\n","       [ 9984.729 ],\n","       [12676.253 ],\n","       [11063.757 ],\n","       [14901.079 ],\n","       [ 8660.417 ],\n","       [ 7894.0557],\n","       [10263.718 ],\n","       [12525.696 ],\n","       [ 8883.549 ],\n","       [10290.519 ],\n","       [10979.836 ],\n","       [13744.071 ],\n","       [ 8689.724 ],\n","       [18860.639 ],\n","       [12508.257 ],\n","       [ 8910.513 ],\n","       [ 8022.5703],\n","       [17173.643 ],\n","       [ 9028.397 ],\n","       [12626.946 ],\n","       [11401.464 ],\n","       [ 7811.182 ],\n","       [11973.109 ],\n","       [ 8069.356 ],\n","       [10435.203 ],\n","       [11573.398 ],\n","       [21587.822 ],\n","       [ 9883.386 ],\n","       [ 9186.905 ],\n","       [12125.888 ],\n","       [ 6757.5   ],\n","       [17395.008 ],\n","       [ 7100.0757],\n","       [ 8349.435 ],\n","       [19157.146 ],\n","       [ 7866.088 ],\n","       [11794.29  ],\n","       [ 9661.045 ],\n","       [16794.293 ],\n","       [17021.988 ],\n","       [ 8124.653 ],\n","       [ 8510.381 ],\n","       [ 8880.397 ],\n","       [ 8330.731 ],\n","       [15628.428 ],\n","       [ 9010.282 ],\n","       [11702.706 ],\n","       [ 9222.569 ],\n","       [16343.312 ],\n","       [11675.825 ],\n","       [ 9174.157 ],\n","       [ 8940.395 ],\n","       [10211.452 ],\n","       [ 9711.911 ],\n","       [12609.608 ],\n","       [14791.54  ],\n","       [19520.691 ],\n","       [12647.04  ],\n","       [ 8927.203 ],\n","       [ 7769.061 ],\n","       [ 8059.099 ],\n","       [ 7888.7515],\n","       [12620.677 ],\n","       [ 9676.079 ]], dtype=float32)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["y_pred"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":486,"status":"ok","timestamp":1696293448750,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"d7WEwToL05uQ","outputId":"36f1d3ba-12fd-42a0-a1e5-d7a3e70ac7a2"},"outputs":[{"data":{"text/plain":["3"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["len(model.layers)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":476,"status":"ok","timestamp":1696293451778,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"zBZApEbWsRj0","outputId":"e274c8f0-9915-4b3b-8ec9-7dc39c2230ef"},"outputs":[{"data":{"text/plain":["21595758.514166303"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["#calculate Mean Square Error\n","MSE = np.square(np.subtract(yTest,y_pred)).mean()\n","MSE"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":412,"status":"ok","timestamp":1696293455306,"user":{"displayName":"Kitsana WAIYAMAI","userId":"08238276839217665641"},"user_tz":-420},"id":"EEK6kI2yd45c","outputId":"fcbfafe5-088e-4e6f-b87d-90d1467c48f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["4647.123681823661\n"]}],"source":["RMSE = math.sqrt(MSE)\n","print(RMSE)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1MoKa5mMAusLUoMlllLT_f7vXoME8pSaL","timestamp":1681654846903}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":0}
